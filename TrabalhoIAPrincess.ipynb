{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJ65w4xavLef"
      },
      "source": [
        "# Instalando e importando os dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vHqvTGk4kgB",
        "outputId": "4dd356b3-929e-46c4-a31e-53f157d43384"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "id": "PeWApVoe4aVP",
        "outputId": "d4c0868f-5611-44f9-c52b-f31bf6342752"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0d3ba687-f560-4c39-a6d4-57c04dbe2a06\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0d3ba687-f560-4c39-a6d4-57c04dbe2a06\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m28wtM4Fq4IG"
      },
      "outputs": [],
      "source": [
        "#--------------------------------------------------\n",
        "# Importanto as bibliotecas Python necessarias ao experimento\n",
        "# Manipulacao matricial, matemática e visualizacao grafica\n",
        "#--------------------------------------------------\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from math import sqrt\n",
        "#--------------------------------------------------\n",
        "# Processamento dos dados\n",
        "#--------------------------------------------------\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#--------------------------------------------------\n",
        "# Carregando o modelo inteligente e as metricas de desempenho\n",
        "#--------------------------------------------------\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "#--------------------------------------------------\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "MYr2viPixqTb"
      },
      "outputs": [],
      "source": [
        "# Definição das colunas para o DataFrame\n",
        "columns = {\n",
        "    'Phoenix Feather': [],\n",
        "    'Unicorn Horn': [],\n",
        "    'Dragon\\'s Blood': [],\n",
        "    'Mermaid Tears': [],\n",
        "    'Fairy Dust': [],\n",
        "    'Goblin Toes': [],\n",
        "    'Witch\\'s Brew': [],\n",
        "    'Griffin Claw': [],\n",
        "    'Troll Hair': [],\n",
        "    'Kraken Ink': [],\n",
        "    'Minotaur Horn': [],\n",
        "    'Basilisk Scale': [],\n",
        "    'Chimera Fang': [],\n",
        "    'Cured': []\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "# Leitura do arquivo CSV 'princess.csv' com as colunas definidas\n",
        "df = pd.read_csv('princess2.csv', names = columns)\n",
        "\n",
        "\n",
        "# Impressão da dimensão dos dados\n",
        "print(\"Dimensão dos dados:\")\n",
        "print(df.shape)\n",
        "\n",
        "# Impressão da estatística descritiva das variáveis\n",
        "print(\"Estatística descritiva das variáveis:\")\n",
        "df.describe().transpose()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ZDtGvTi-AdWg"
      },
      "outputs": [],
      "source": [
        "#--------------------------------------------------\n",
        "#Criando matrizes para os recursos e a variável de resposta\n",
        "#A primeira linha de código cria um objeto da variável de destino chamado\n",
        "#'target_column'.\n",
        "#--------------------------------------------------\n",
        "#A segunda linha nos dá a lista de todos os recursos, excluindo a variável de\n",
        "#destino 'Diagnosis'\n",
        "#A terceira linha normaliza os preditores.\n",
        "#A quarta linha exibe o resumo dos dados normalizados.\n",
        "#--------------------------------------------------\n",
        "#Podemos ver que todas as variáveis ​​independentes agora foram dimensionadas entre 0 e 1.\n",
        "#A variável de destino permanece inalterada.\n",
        "#--------------------------------------------------\n",
        "target_column = ['Cured']\n",
        "#--------------------------------------------------\n",
        "predictors = list(set(list(df.columns))-set(target_column))\n",
        "\n",
        "for col in predictors:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "df[predictors] = df[predictors]/df[predictors].max()\n",
        "print(\"Estatística descritiva das variáveis normalizadas:\")\n",
        "df[predictors].describe().transpose()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKy1KhbczN_9"
      },
      "source": [
        "Criando os conjuntos de dados de treinamento e teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "yC8sm4CUA0aD"
      },
      "outputs": [],
      "source": [
        "#As primeiras linhas de código abaixo criam arrays das variáveis ​​independentes\n",
        "# entrada_X e dependentes (saidaDesejada_y), respectivamente.\n",
        "#--------------------------------------------------\n",
        "#A terceira linha divide os dados em conjunto de dados de treinamento e teste,\n",
        "#A quarta linha imprime a forma dos dados de treinamento e teste.\n",
        "\n",
        "entrada_X = df[predictors].values\n",
        "saidaDesejada_y = df[target_column].values\n",
        "\n",
        "# Aplicando a funcao train_test_split para dividir o conjunto original em 70% para treindo e 30% para teste. E fixamos o random_state de 42 para fixar os valores do conjunto\n",
        "X_train, X_test, y_train, y_test = train_test_split(entrada_X, saidaDesejada_y, test_size=0.3, random_state=42)\n",
        "\n",
        "\n",
        "print(\"Conjunto de treinamento:\")\n",
        "print(X_train.shape);\n",
        "print(\"Conjunto de teste:\")\n",
        "print(X_test.shape)\n",
        "\n",
        "# Dividindo o conjunto de treinamento em dois subconjuntos\n",
        "X_train1, X_train2, y_train1, y_train2 = train_test_split(X_train, y_train, test_size=0.5, random_state=42)\n",
        "\n",
        "# Imprimindo as formas dos novos subconjuntos\n",
        "print(\"Subconjunto 1 do conjunto de treinamento:\")\n",
        "print(X_train1.shape)\n",
        "print(\"Subconjunto 2 do conjunto de treinamento:\")\n",
        "print(X_train2.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vhqIPW7y4HV"
      },
      "source": [
        "#Função que calcula a média das métricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UctQz_cmlxf3"
      },
      "outputs": [],
      "source": [
        "# Função para calcular a média das métricas\n",
        "def media (lista):\n",
        "  # Calculando a média para cada métrica\n",
        "  mean_accuracy = np.mean([x[0] for x in lista])\n",
        "  mean_recall = np.mean([x[1] for x in lista])\n",
        "  mean_precision = np.mean([x[2] for x in lista])\n",
        "  mean_f1 = np.mean([x[3] for x in lista])\n",
        "\n",
        "  print(f'Média de Acurácia: {mean_accuracy}')\n",
        "  print(f'Média de Recall: {mean_recall}')\n",
        "  print(f'Média de Precisão: {mean_precision}')\n",
        "  print(f'Média de F1 Score: {mean_f1}')\n",
        "\n",
        "  #print('------------------------------')\n",
        "  #print('--- Matriz de Confusão ---')\n",
        "  #print('------------------------------')\n",
        "  #pd.DataFrame(confusion_matrix(saida1, saida2),\n",
        "   #            index=['neg', 'pos'], columns=['pred_neg', 'pred_pos'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tkqnrRY5Kq8"
      },
      "source": [
        "#Rede Neural"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySTfzChlywc8"
      },
      "source": [
        "Função Rede Neural"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "lAyLVFeO1Chx"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-learn\n",
        "import sklearn\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Listas para armazenar os resultados das métricas\n",
        "lista1 = []\n",
        "lista2 = []\n",
        "lista3 = []\n",
        "\n",
        "def redeNeural(neuronios,ativacao) :\n",
        "\n",
        "  imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "  # Loop para realizar o procedimento 100 vezes\n",
        "  for i in range(1, 100) :\n",
        "\n",
        "    #Inicializa o classificador MLP com o número de neurônios e função de ativação especificados\n",
        "    mlp = MLPClassifier(hidden_layer_sizes=(neuronios), activation=ativacao, solver='adam', max_iter=500, random_state=None)\n",
        "\n",
        "    # Treina o modelo no primeiro conjunto de treinamento\n",
        "    X_train1_imputed = imputer.fit_transform(X_train1)\n",
        "    mlp.fit(X_train1_imputed, y_train1)\n",
        "    predict_train = mlp.predict(X_train1_imputed)\n",
        "\n",
        "    saidaPrevista_treino = predict_train\n",
        "    saidaDesejada_treino =  y_train1\n",
        "\n",
        "    # Verifica as métricas de desempenho no primeiro conjunto de treinamento\n",
        "    accuracy_train = accuracy_score(saidaDesejada_treino, saidaPrevista_treino)\n",
        "    recall_train = recall_score(saidaDesejada_treino, saidaPrevista_treino, average='macro') # Change average to 'macro'\n",
        "    precision_train = precision_score(saidaDesejada_treino, saidaPrevista_treino, average='macro') # Change average to 'macro'\n",
        "    f1_train = f1_score(saidaDesejada_treino, saidaPrevista_treino, average='macro') # Change average to 'macro'\n",
        "    lista1.append((accuracy_train,recall_train,precision_train,f1_train))\n",
        "\n",
        "    # Treina o modelo no segundo conjunto de treinamento\n",
        "    X_train2_imputed = imputer.fit_transform(X_train2)\n",
        "    mlp.fit(X_train2_imputed, y_train2)\n",
        "    predict_train = mlp.predict(X_train2_imputed)\n",
        "\n",
        "    saidaPrevista_treino = predict_train\n",
        "    saidaDesejada_treino =  y_train2\n",
        "\n",
        "    # Verifica as métricas de desempenho no segundo conjunto de treinamento\n",
        "    accuracy_train = accuracy_score(saidaDesejada_treino, saidaPrevista_treino)\n",
        "    recall_train = recall_score(saidaDesejada_treino, saidaPrevista_treino, average='macro') # Change average to 'macro'\n",
        "    precision_train = precision_score(saidaDesejada_treino, saidaPrevista_treino, average='macro') # Change average to 'macro'\n",
        "    f1_train = f1_score(saidaDesejada_treino, saidaPrevista_treino, average='macro') # Change average to 'macro'\n",
        "    lista2.append((accuracy_train,recall_train,precision_train,f1_train))\n",
        "\n",
        "\n",
        "\n",
        "  # Treina o modelo no conjunto de teste com uma configuração fixa (random_state 42)\n",
        "  X_test_imputed = imputer.fit_transform(X_test)\n",
        "  mlp = MLPClassifier(hidden_layer_sizes=(neuronios), activation=ativacao, solver='adam', max_iter=500, random_state=42)\n",
        "  mlp.fit(X_test_imputed,y_test)\n",
        "  predict_test = mlp.predict(X_test_imputed)\n",
        "  saidaPrevista_test = predict_test\n",
        "  saidaDesejada_test = y_test\n",
        "\n",
        "  # Imprime as médias das métricas para o primeiro conjunto de treinamento\n",
        "  print(\"\\nConjunto de treinamento 1:\")\n",
        "  media(lista1)\n",
        "\n",
        "  # Imprime as médias das métricas para o segundo conjunto de treinamento\n",
        "  print(\"\\nConjunto de treinamento 2:\")\n",
        "  media(lista2)\n",
        "\n",
        "  # Verifica as métricas de desempenho no conjunto de teste\n",
        "  accuracy_test = accuracy_score(saidaDesejada_test, saidaPrevista_test)\n",
        "  recall_test = recall_score(saidaDesejada_test, saidaPrevista_test, average='macro') # Change average to 'macro'\n",
        "  precision_test = precision_score(saidaDesejada_test, saidaPrevista_test, average='macro') # Change average to 'macro'\n",
        "  f1_test = f1_score(saidaDesejada_test, saidaPrevista_test, average='macro') # Change average to 'macro'\n",
        "\n",
        "\n",
        "\n",
        "  # Imprime as métricas de desempenho no conjunto de teste\n",
        "  print('------------------------------')\n",
        "  print('------------------------------')\n",
        "  print('Conjunto de teste')\n",
        "  print('Acurácia: ', accuracy_test)\n",
        "  print('Recall: ', recall_test)\n",
        "  print('Precision: ', precision_test)\n",
        "  print('f1 Score: ', f1_test)\n",
        "  print('------------------------------')\n",
        "  print('------------------------------')\n",
        "\n",
        "  return lista1, lista2, lista3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtxD2n0Mxqkp"
      },
      "source": [
        "Chama a função redeNeural de 5 a 100 neurônios na camada oculta e usando a função de ativação tangente hiperbólica (tanh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "CALEVCCWReHF"
      },
      "outputs": [],
      "source": [
        "l1,l2,l3 = redeNeural(5,'tanh')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "EEofnh6eSFbn"
      },
      "outputs": [],
      "source": [
        "l1,l2,l3 = redeNeural(20,'tanh')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ig9b9QsqSFmX"
      },
      "outputs": [],
      "source": [
        "l1,l2,l3 = redeNeural(30,'tanh')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "lDJEAy76SFuZ"
      },
      "outputs": [],
      "source": [
        "l1,l2,l3 = redeNeural(50,'tanh')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "IPQNOHSvSGCI"
      },
      "outputs": [],
      "source": [
        "l1,l2,l3 = redeNeural(100,'tanh')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoafjT2ryJlH"
      },
      "source": [
        "Chama a função redeNeural de 5 a 100 neurônios na camada oculta e usando a função de ativação identidade (identity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "95CiWRA2SGIG"
      },
      "outputs": [],
      "source": [
        "l1,l2,l3 = redeNeural(5,'identity')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "vJD7XZTTSGMH"
      },
      "outputs": [],
      "source": [
        "l1,l2,l3 = redeNeural(20,'identity')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "CmVvy41ySGOv"
      },
      "outputs": [],
      "source": [
        "l1,l2,l3 = redeNeural(30,'identity')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "PSVr2bLeSGRP"
      },
      "outputs": [],
      "source": [
        "l1,l2,l3 = redeNeural(50,'identity')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-Sj_N4p0SGTn"
      },
      "outputs": [],
      "source": [
        "l1,l2,l3 = redeNeural(100,'identity')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gB_9c61FyeHs"
      },
      "source": [
        "Chama a função redeNeural de 5 a 100 neurônios na camada oculta e usando a função de ativação ReLU (Rectified Linear Unit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ieZrikRmSGWP"
      },
      "outputs": [],
      "source": [
        "l1,l2,l3 = redeNeural(5,'relu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9MyNyHm1SGYv"
      },
      "outputs": [],
      "source": [
        "l1,l2,l3 = redeNeural(20,'relu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "fm7YOJkPSGhG"
      },
      "outputs": [],
      "source": [
        "l1,l2,l3 = redeNeural(30,'relu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "t3mCFetbSGj3"
      },
      "outputs": [],
      "source": [
        "l1,l2,l3 = redeNeural(50,'relu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "gnwR55KsSGp7"
      },
      "outputs": [],
      "source": [
        "l1,l2,l3 = redeNeural(100,'relu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxeDGHTHYE2s"
      },
      "source": [
        "#KNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwY3HWAUuFH0"
      },
      "source": [
        "Função KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afIIGVzCYLy9"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Listas para armazenar os resultados das métricas\n",
        "lista1 = []\n",
        "lista2 = []\n",
        "lista3 = []\n",
        "lista4 = []\n",
        "\n",
        "def knn(n_neighbors):\n",
        "    # Criando o imputador para preencher valores ausentes com a média\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "\n",
        "    # Aplicando o imputador ao conjunto de treinamento e teste\n",
        "    X_train_imputed = imputer.fit_transform(X_train)\n",
        "    X_test_imputed = imputer.transform(X_test)\n",
        "\n",
        "    # Descobrir quais rótulos estão presentes\n",
        "    unique_labels = np.unique(np.concatenate((y_train, y_test)))\n",
        "\n",
        "    # Loop para realizar o procedimento 100 vezes\n",
        "    for i in range(100):\n",
        "        # Divide o conjunto de treinamento em dois subconjuntos, sem random_state para aleatoriedade\n",
        "        X_train1, X_train2, y_train1, y_train2 = train_test_split(X_train_imputed, y_train, test_size=0.5, random_state=None)\n",
        "\n",
        "        # Conjunto de treinamento 1\n",
        "        knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "        knn.fit(X_train1, y_train1)\n",
        "        y_pred = knn.predict(X_train1)\n",
        "        accuracy_train3 = accuracy_score(y_train1, y_pred)\n",
        "        recall_train3 = recall_score(y_train1, y_pred, average='weighted')\n",
        "        precision_train3 = precision_score(y_train1, y_pred, average='weighted')\n",
        "        f1_train3 = f1_score(y_train1, y_pred, average='weighted')\n",
        "        lista3.append((accuracy_train3, recall_train3, precision_train3, f1_train3))\n",
        "\n",
        "        # Conjunto de treinamento 2\n",
        "        knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "        knn.fit(X_train2, y_train2)\n",
        "        y_pred = knn.predict(X_train2)\n",
        "        accuracy_train4 = accuracy_score(y_train2, y_pred)\n",
        "        recall_train4 = recall_score(y_train2, y_pred, average='weighted')\n",
        "        precision_train4 = precision_score(y_train2, y_pred, average='weighted')\n",
        "        f1_train4 = f1_score(y_train2, y_pred, average='weighted')\n",
        "        lista4.append((accuracy_train4, recall_train4, precision_train4, f1_train4))\n",
        "\n",
        "        # Conjunto de teste 1\n",
        "        knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "        knn.fit(X_train1, y_train1)\n",
        "        y_pred = knn.predict(X_test_imputed)\n",
        "        accuracy_train1 = accuracy_score(y_test, y_pred)\n",
        "        recall_train1 = recall_score(y_test, y_pred, average='weighted')\n",
        "        precision_train1 = precision_score(y_test, y_pred, average='weighted')\n",
        "        f1_train1 = f1_score(y_test, y_pred, average='weighted')\n",
        "        lista1.append((accuracy_train1, recall_train1, precision_train1, f1_train1))\n",
        "\n",
        "        # Conjunto de teste 2\n",
        "        knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "        knn.fit(X_train2, y_train2)\n",
        "        y_pred = knn.predict(X_test_imputed)\n",
        "        accuracy_train2 = accuracy_score(y_test, y_pred)\n",
        "        recall_train2 = recall_score(y_test, y_pred, average='weighted')\n",
        "        precision_train2 = precision_score(y_test, y_pred, average='weighted')\n",
        "        f1_train2 = f1_score(y_test, y_pred, average='weighted')\n",
        "        lista2.append((accuracy_train2, recall_train2, precision_train2, f1_train2))\n",
        "\n",
        "    # Imprime as médias das métricas para cada conjunto\n",
        "    print('Conjunto de teste 1')\n",
        "    media(lista1)\n",
        "    print('\\nConjunto de teste 2')\n",
        "    media(lista2)\n",
        "    print('\\nConjunto de treinamento 1')\n",
        "    media(lista3)\n",
        "    print('\\nConjunto de treinamento 2')\n",
        "    media(lista4)\n",
        "\n",
        "    return lista1, lista2, lista3, lista4\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ityh1NxUvHcG"
      },
      "source": [
        "Executando a função KNN e Imprimindo as médias das métricas para cada conjunto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "QfqkDrNlvRV1"
      },
      "outputs": [],
      "source": [
        "# Executa a função KNN e armazena os resultados\n",
        "lista1,lista2,lista3,lista4 = knn(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lista1,lista2,lista3,lista4 = knn(3)"
      ],
      "metadata": {
        "id": "BtOYwACwwI5b",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista1,lista2,lista3,lista4 = knn(5)"
      ],
      "metadata": {
        "id": "cGYCQdrmwNyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista1,lista2,lista3,lista4 = knn(7)"
      ],
      "metadata": {
        "id": "GY51-0xTwNra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista1,lista2,lista3,lista4 = knn(9)"
      ],
      "metadata": {
        "id": "saWaDPvewNjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista1,lista2,lista3,lista4 = knn(11)"
      ],
      "metadata": {
        "id": "9bX-svAfwNcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista1,lista2,lista3,lista4 = knn(13)"
      ],
      "metadata": {
        "id": "70evJsp4wNUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista1,lista2,lista3,lista4 = knn(15)"
      ],
      "metadata": {
        "id": "yWLDUTopwNOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista1,lista2,lista3,lista4 = knn(17)"
      ],
      "metadata": {
        "id": "FykyqFyGwNHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista1,lista2,lista3,lista4 = knn(19)"
      ],
      "metadata": {
        "id": "ZILvDZYUwNA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista1,lista2,lista3,lista4 = knn(21)"
      ],
      "metadata": {
        "id": "lk7cXzzOwM5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista1,lista2,lista3,lista4 = knn(23)"
      ],
      "metadata": {
        "id": "Nrsg7vr5wMx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista1,lista2,lista3,lista4 = knn(25)"
      ],
      "metadata": {
        "id": "HXriPvKjwMnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista1,lista2,lista3,lista4 = knn(27)"
      ],
      "metadata": {
        "id": "PxMLwUziwMd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista1,lista2,lista3,lista4 = knn(29)"
      ],
      "metadata": {
        "id": "sa4wVSWXwMM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLjPXVzW4vYv"
      },
      "source": [
        "#Árvore de decisão"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq0JyK4FdAf5"
      },
      "source": [
        "Função de Árvore de decisão"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsK09fj8chTP"
      },
      "source": [
        "Racionalização dos Parâmetros Escolhidos:\n",
        "\n",
        "  max_depth: Limita a profundidade máxima da árvore para evitar overfitting. Valores como 10, 20 e 30 são escolhas razoáveis, pois controlam a complexidade da árvore.\n",
        "\n",
        "  min_samples_split: Define o número mínimo de amostras necessárias para dividir um nó. Valores maiores como 5 ou 10 podem ajudar a simplificar a árvore, reduzindo o overfitting.\n",
        "  \n",
        "  min_samples_leaf: Define o número mínimo de amostras permitidas em uma folha. Valores maiores como 2 ou 4 ajudam a regularizar o modelo, evitando folhas com muito poucas amostras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upbW6w7eS4hh"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Listas para armazenar os resultados das métricas\n",
        "lista1 = []  # Resultados para conjunto de teste com o primeiro subconjunto de treinamento\n",
        "lista2 = []  # Resultados para conjunto de teste com o segundo subconjunto de treinamento\n",
        "lista3 = []  # Resultados para o primeiro subconjunto de treinamento\n",
        "lista4 = []  # Resultados para o segundo subconjunto de treinamento\n",
        "\n",
        "def decision_tree(X_train, y_train, X_test, y_test, max_depth, min_samples_split, min_samples_leaf):\n",
        "    # Criando o imputador para preencher valores ausentes com a média\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "\n",
        "    # Aplicando o imputador ao conjunto de treinamento e teste\n",
        "    X_train_imputed = imputer.fit_transform(X_train)\n",
        "    X_test_imputed = imputer.transform(X_test)\n",
        "\n",
        "    # Transformando os vetores de rótulos para arrays unidimensionais\n",
        "    y_train = np.ravel(y_train)\n",
        "    y_test = np.ravel(y_test)\n",
        "\n",
        "    # Descobrir quais rótulos estão presentes\n",
        "    unique_labels = np.unique(np.concatenate((y_train, y_test)))\n",
        "\n",
        "    # Listas para armazenar os resultados das métricas\n",
        "    lista1 = []  # Resultados para conjunto de teste com o primeiro subconjunto de treinamento\n",
        "    lista2 = []  # Resultados para conjunto de teste com o segundo subconjunto de treinamento\n",
        "    lista3 = []  # Resultados para o primeiro subconjunto de treinamento\n",
        "    lista4 = []  # Resultados para o segundo subconjunto de treinamento\n",
        "\n",
        "    # Loop para realizar o procedimento 100 vezes\n",
        "    for i in range(100):\n",
        "        # Divide o conjunto de treinamento em dois subconjuntos, sem random_state para aleatoriedade\n",
        "        X_train1, X_train2, y_train1, y_train2 = train_test_split(X_train_imputed, y_train, test_size=0.5, random_state=None)\n",
        "\n",
        "        # Conjunto de treinamento 1\n",
        "        dt = DecisionTreeClassifier(max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n",
        "        dt.fit(X_train1, y_train1)\n",
        "        y_pred = dt.predict(X_train1)\n",
        "        accuracy_train3 = accuracy_score(y_train1, y_pred)\n",
        "        recall_train3 = recall_score(y_train1, y_pred, average='weighted', labels=unique_labels)\n",
        "        precision_train3 = precision_score(y_train1, y_pred, average='weighted', labels=unique_labels)\n",
        "        f1_train3 = f1_score(y_train1, y_pred, average='weighted', labels=unique_labels)\n",
        "        lista3.append((accuracy_train3, recall_train3, precision_train3, f1_train3))\n",
        "\n",
        "        # Conjunto de treinamento 2\n",
        "        dt = DecisionTreeClassifier(max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n",
        "        dt.fit(X_train2, y_train2)\n",
        "        y_pred = dt.predict(X_train2)\n",
        "        accuracy_train4 = accuracy_score(y_train2, y_pred)\n",
        "        recall_train4 = recall_score(y_train2, y_pred, average='weighted', labels=unique_labels)\n",
        "        precision_train4 = precision_score(y_train2, y_pred, average='weighted', labels=unique_labels)\n",
        "        f1_train4 = f1_score(y_train2, y_pred, average='weighted', labels=unique_labels)\n",
        "        lista4.append((accuracy_train4, recall_train4, precision_train4, f1_train4))\n",
        "\n",
        "        # Conjunto de teste 1\n",
        "        dt = DecisionTreeClassifier(max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n",
        "        dt.fit(X_train1, y_train1)\n",
        "        y_pred = dt.predict(X_test_imputed)\n",
        "        accuracy_train1 = accuracy_score(y_test, y_pred)\n",
        "        recall_train1 = recall_score(y_test, y_pred, average='weighted', labels=unique_labels)\n",
        "        precision_train1 = precision_score(y_test, y_pred, average='weighted', labels=unique_labels)\n",
        "        f1_train1 = f1_score(y_test, y_pred, average='weighted', labels=unique_labels)\n",
        "        lista1.append((accuracy_train1, recall_train1, precision_train1, f1_train1))\n",
        "\n",
        "        # Conjunto de teste 2\n",
        "        dt = DecisionTreeClassifier(max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n",
        "        dt.fit(X_train2, y_train2)\n",
        "        y_pred = dt.predict(X_test_imputed)\n",
        "        accuracy_train2 = accuracy_score(y_test, y_pred)\n",
        "        recall_train2 = recall_score(y_test, y_pred, average='weighted', labels=unique_labels)\n",
        "        precision_train2 = precision_score(y_test, y_pred, average='weighted', labels=unique_labels)\n",
        "        f1_train2 = f1_score(y_test, y_pred, average='weighted', labels=unique_labels)\n",
        "        lista2.append((accuracy_train2, recall_train2, precision_train2, f1_train2))\n",
        "\n",
        "    # Imprime as médias das métricas para cada conjunto\n",
        "    print('Conjunto de teste 1')\n",
        "    media(lista1)\n",
        "    print('\\nConjunto de teste 2')\n",
        "    media(lista2)\n",
        "    print('\\nConjunto de treinamento 1')\n",
        "    media(lista3)\n",
        "    print('\\nConjunto de treinamento 2')\n",
        "    media(lista4)\n",
        "\n",
        "    return lista1, lista2, lista3, lista4\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6wMvzsC6ipb"
      },
      "source": [
        "Chamando a árvore de decisão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbpkXKhU6mNC",
        "outputId": "5d3edbba-e189-4d5b-89cb-8d365dc01ae1",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conjunto de teste 1\n",
            "Média de Acurácia: 0.8254131054131054\n",
            "Média de Recall: 0.8254131054131054\n",
            "Média de Precisão: 0.8270934273527307\n",
            "Média de F1 Score: 0.8252628636304837\n",
            "\n",
            "Conjunto de teste 2\n",
            "Média de Acurácia: 0.8275925925925925\n",
            "Média de Recall: 0.8275925925925925\n",
            "Média de Precisão: 0.8298409670064625\n",
            "Média de F1 Score: 0.8273675391389778\n",
            "\n",
            "Conjunto de treinamento 1\n",
            "Média de Acurácia: 0.97580684596577\n",
            "Média de Recall: 0.97580684596577\n",
            "Média de Precisão: 0.9765659574667018\n",
            "Média de F1 Score: 0.9757891075189\n",
            "\n",
            "Conjunto de treinamento 2\n",
            "Média de Acurácia: 0.976002444987775\n",
            "Média de Recall: 0.976002444987775\n",
            "Média de Precisão: 0.9767633479071317\n",
            "Média de F1 Score: 0.9759852890034307\n"
          ]
        }
      ],
      "source": [
        "# Chame a função e obtenha os resultados\n",
        "resultados = decision_tree(X_train, y_train, X_test, y_test, None, 2, 2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultados = decision_tree(X_train, y_train, X_test, y_test, 10, 10, 2)"
      ],
      "metadata": {
        "id": "nu9aOXEaxhnj",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31da7667-4a61-41f2-bb4f-1f7e596765f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conjunto de teste 1\n",
            "Média de Acurácia: 0.826111111111111\n",
            "Média de Recall: 0.826111111111111\n",
            "Média de Precisão: 0.8275503633475867\n",
            "Média de F1 Score: 0.8259767880414007\n",
            "\n",
            "Conjunto de teste 2\n",
            "Média de Acurácia: 0.8220370370370371\n",
            "Média de Recall: 0.8220370370370371\n",
            "Média de Precisão: 0.8237776194074928\n",
            "Média de F1 Score: 0.8218673067420155\n",
            "\n",
            "Conjunto de treinamento 1\n",
            "Média de Acurácia: 0.9536919315403424\n",
            "Média de Recall: 0.9536919315403424\n",
            "Média de Precisão: 0.9542403752303121\n",
            "Média de F1 Score: 0.9536681080642689\n",
            "\n",
            "Conjunto de treinamento 2\n",
            "Média de Acurácia: 0.9529462102689485\n",
            "Média de Recall: 0.9529462102689485\n",
            "Média de Precisão: 0.9535563860447828\n",
            "Média de F1 Score: 0.9529164878229119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultados = decision_tree(X_train, y_train, X_test, y_test, 20, 5, 1)"
      ],
      "metadata": {
        "id": "XcErBO98xkrL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b255f2c-056e-4703-fe53-067f4febf11d",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conjunto de teste 1\n",
            "Média de Acurácia: 0.8295014245014245\n",
            "Média de Recall: 0.8295014245014245\n",
            "Média de Precisão: 0.830232365579671\n",
            "Média de F1 Score: 0.8294394498321567\n",
            "\n",
            "Conjunto de teste 2\n",
            "Média de Acurácia: 0.8260683760683761\n",
            "Média de Recall: 0.8260683760683761\n",
            "Média de Precisão: 0.826762806800162\n",
            "Média de F1 Score: 0.8260123386151524\n",
            "\n",
            "Conjunto de treinamento 1\n",
            "Média de Acurácia: 0.9867481662591686\n",
            "Média de Recall: 0.9867481662591686\n",
            "Média de Precisão: 0.9868228874202165\n",
            "Média de F1 Score: 0.9867466903501964\n",
            "\n",
            "Conjunto de treinamento 2\n",
            "Média de Acurácia: 0.9865403422982884\n",
            "Média de Recall: 0.9865403422982884\n",
            "Média de Precisão: 0.9866147068539851\n",
            "Média de F1 Score: 0.9865384963652808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultados = decision_tree(X_train, y_train, X_test, y_test,40, 2, 4)"
      ],
      "metadata": {
        "id": "BdZtRNZ-xkjW",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "340c6f84-6c0c-42a5-eaba-aa9ff9e52385"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conjunto de teste 1\n",
            "Média de Acurácia: 0.8294444444444444\n",
            "Média de Recall: 0.8294444444444444\n",
            "Média de Precisão: 0.8308824708727256\n",
            "Média de F1 Score: 0.8293163098534225\n",
            "\n",
            "Conjunto de teste 2\n",
            "Média de Acurácia: 0.8285897435897435\n",
            "Média de Recall: 0.8285897435897435\n",
            "Média de Precisão: 0.8301487067582991\n",
            "Média de F1 Score: 0.8284488873566004\n",
            "\n",
            "Conjunto de treinamento 1\n",
            "Média de Acurácia: 0.9498288508557456\n",
            "Média de Recall: 0.9498288508557456\n",
            "Média de Precisão: 0.9503422136565594\n",
            "Média de F1 Score: 0.9498004631019441\n",
            "\n",
            "Conjunto de treinamento 2\n",
            "Média de Acurácia: 0.9493031784841078\n",
            "Média de Recall: 0.9493031784841078\n",
            "Média de Precisão: 0.9499041042347409\n",
            "Média de F1 Score: 0.9492740447153141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultados = decision_tree(X_train, y_train, X_test, y_test,10, 5, 4)"
      ],
      "metadata": {
        "id": "oFQJMD6oxhlY",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "511484ef-61a5-4248-ff70-c61b1dd1d187"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conjunto de teste 1\n",
            "Média de Acurácia: 0.8275356125356125\n",
            "Média de Recall: 0.8275356125356125\n",
            "Média de Precisão: 0.8290528761119431\n",
            "Média de F1 Score: 0.8273969057839986\n",
            "\n",
            "Conjunto de teste 2\n",
            "Média de Acurácia: 0.8285612535612537\n",
            "Média de Recall: 0.8285612535612537\n",
            "Média de Precisão: 0.8302392604900034\n",
            "Média de F1 Score: 0.8284084248702789\n",
            "\n",
            "Conjunto de treinamento 1\n",
            "Média de Acurácia: 0.9481295843520783\n",
            "Média de Recall: 0.9481295843520783\n",
            "Média de Precisão: 0.9486902454830478\n",
            "Média de F1 Score: 0.9480980933303544\n",
            "\n",
            "Conjunto de treinamento 2\n",
            "Média de Acurácia: 0.9472127139364304\n",
            "Média de Recall: 0.9472127139364304\n",
            "Média de Precisão: 0.9477897105293063\n",
            "Média de F1 Score: 0.9471830607942576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultados = decision_tree(X_train, y_train, X_test, y_test,40, 10, 2)"
      ],
      "metadata": {
        "id": "GEWCG7UIxhiy",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7f84bb0-91f7-4825-c0f5-f4c5ec72e8b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conjunto de teste 1\n",
            "Média de Acurácia: 0.8251566951566953\n",
            "Média de Recall: 0.8251566951566953\n",
            "Média de Precisão: 0.8268942011020571\n",
            "Média de F1 Score: 0.8249903421775775\n",
            "\n",
            "Conjunto de teste 2\n",
            "Média de Acurácia: 0.8254131054131055\n",
            "Média de Recall: 0.8254131054131055\n",
            "Média de Precisão: 0.8267894202598849\n",
            "Média de F1 Score: 0.8252891463504243\n",
            "\n",
            "Conjunto de treinamento 1\n",
            "Média de Acurácia: 0.9550488997555011\n",
            "Média de Recall: 0.9550488997555011\n",
            "Média de Precisão: 0.955663787738422\n",
            "Média de F1 Score: 0.9550182778902679\n",
            "\n",
            "Conjunto de treinamento 2\n",
            "Média de Acurácia: 0.9529951100244497\n",
            "Média de Recall: 0.9529951100244497\n",
            "Média de Precisão: 0.9535218184039108\n",
            "Média de F1 Score: 0.9529710204303065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultados = decision_tree(X_train, y_train, X_test, y_test,None, 2, 1)"
      ],
      "metadata": {
        "id": "gj-d2NF0xhgY",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe589664-0b4a-440e-94da-ac179b9fe965"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conjunto de teste 1\n",
            "Média de Acurácia: 0.8259686609686611\n",
            "Média de Recall: 0.8259686609686611\n",
            "Média de Precisão: 0.8265504452784396\n",
            "Média de F1 Score: 0.8259121195378902\n",
            "\n",
            "Conjunto de teste 2\n",
            "Média de Acurácia: 0.8297293447293447\n",
            "Média de Recall: 0.8297293447293447\n",
            "Média de Precisão: 0.8302545730991198\n",
            "Média de F1 Score: 0.8296808596891855\n",
            "\n",
            "Conjunto de treinamento 1\n",
            "Média de Acurácia: 1.0\n",
            "Média de Recall: 1.0\n",
            "Média de Precisão: 1.0\n",
            "Média de F1 Score: 1.0\n",
            "\n",
            "Conjunto de treinamento 2\n",
            "Média de Acurácia: 1.0\n",
            "Média de Recall: 1.0\n",
            "Média de Precisão: 1.0\n",
            "Média de F1 Score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultados = decision_tree(X_train, y_train, X_test, y_test,30, 2, 2)"
      ],
      "metadata": {
        "id": "Eo1EJDyfxheD",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed212582-0303-4522-8039-5bb845e3724e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conjunto de teste 1\n",
            "Média de Acurácia: 0.8282763532763533\n",
            "Média de Recall: 0.8282763532763533\n",
            "Média de Precisão: 0.8299685840929589\n",
            "Média de F1 Score: 0.8281261478801692\n",
            "\n",
            "Conjunto de teste 2\n",
            "Média de Acurácia: 0.8270370370370372\n",
            "Média de Recall: 0.8270370370370372\n",
            "Média de Precisão: 0.8288970846142607\n",
            "Média de F1 Score: 0.8268605709319603\n",
            "\n",
            "Conjunto de treinamento 1\n",
            "Média de Acurácia: 0.9763325183374083\n",
            "Média de Recall: 0.9763325183374083\n",
            "Média de Precisão: 0.9770538574640706\n",
            "Média de F1 Score: 0.9763147679661298\n",
            "\n",
            "Conjunto de treinamento 2\n",
            "Média de Acurácia: 0.9757701711491441\n",
            "Média de Recall: 0.9757701711491441\n",
            "Média de Precisão: 0.9765076807056811\n",
            "Média de F1 Score: 0.9757538580493822\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultados = decision_tree(X_train, y_train, X_test, y_test,30, 5, 4)"
      ],
      "metadata": {
        "id": "1CNXaszsxhbO",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b10793b3-f8b7-4af2-b976-bb7047abc386"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conjunto de teste 1\n",
            "Média de Acurácia: 0.8297720797720797\n",
            "Média de Recall: 0.8297720797720797\n",
            "Média de Precisão: 0.8315425415160925\n",
            "Média de F1 Score: 0.8296104040288143\n",
            "\n",
            "Conjunto de teste 2\n",
            "Média de Acurácia: 0.8293162393162393\n",
            "Média de Recall: 0.8293162393162393\n",
            "Média de Precisão: 0.8312107197919754\n",
            "Média de F1 Score: 0.8291439685189019\n",
            "\n",
            "Conjunto de treinamento 1\n",
            "Média de Acurácia: 0.9496210268948656\n",
            "Média de Recall: 0.9496210268948656\n",
            "Média de Precisão: 0.95024273882638\n",
            "Média de F1 Score: 0.9495900791870444\n",
            "\n",
            "Conjunto de treinamento 2\n",
            "Média de Acurácia: 0.9488630806845968\n",
            "Média de Recall: 0.9488630806845968\n",
            "Média de Precisão: 0.9494431973727476\n",
            "Média de F1 Score: 0.9488306397467464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultados = decision_tree(X_train, y_train, X_test, y_test,20, 2, 1)"
      ],
      "metadata": {
        "id": "bGXhEsgUxhMa",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28f6031d-7174-4975-bf61-9338feb6fb42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conjunto de teste 1\n",
            "Média de Acurácia: 0.826980056980057\n",
            "Média de Recall: 0.826980056980057\n",
            "Média de Precisão: 0.8275568398281975\n",
            "Média de F1 Score: 0.8269228782792293\n",
            "\n",
            "Conjunto de teste 2\n",
            "Média de Acurácia: 0.8313247863247861\n",
            "Média de Recall: 0.8313247863247861\n",
            "Média de Precisão: 0.8318958353161702\n",
            "Média de F1 Score: 0.8312761417369181\n",
            "\n",
            "Conjunto de treinamento 1\n",
            "Média de Acurácia: 1.0\n",
            "Média de Recall: 1.0\n",
            "Média de Precisão: 1.0\n",
            "Média de F1 Score: 1.0\n",
            "\n",
            "Conjunto de treinamento 2\n",
            "Média de Acurácia: 1.0\n",
            "Média de Recall: 1.0\n",
            "Média de Precisão: 1.0\n",
            "Média de F1 Score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultados = decision_tree(X_train, y_train, X_test, y_test,40, 5, 1)"
      ],
      "metadata": {
        "id": "V1WIIn8WxhGL",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f701b759-7465-4c19-90dd-5ec814e65606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conjunto de teste 1\n",
            "Média de Acurácia: 0.8264957264957264\n",
            "Média de Recall: 0.8264957264957264\n",
            "Média de Precisão: 0.8271279490001524\n",
            "Média de F1 Score: 0.8264430886448476\n",
            "\n",
            "Conjunto de teste 2\n",
            "Média de Acurácia: 0.8275925925925927\n",
            "Média de Recall: 0.8275925925925927\n",
            "Média de Precisão: 0.8284237086128475\n",
            "Média de F1 Score: 0.8275212158575788\n",
            "\n",
            "Conjunto de treinamento 1\n",
            "Média de Acurácia: 0.9870171149144253\n",
            "Média de Recall: 0.9870171149144253\n",
            "Média de Precisão: 0.9870865835202457\n",
            "Média de F1 Score: 0.9870154938922343\n",
            "\n",
            "Conjunto de treinamento 2\n",
            "Média de Acurácia: 0.9869437652811734\n",
            "Média de Recall: 0.9869437652811734\n",
            "Média de Precisão: 0.9870132560318757\n",
            "Média de F1 Score: 0.9869423667846547\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultados = decision_tree(X_train, y_train, X_test, y_test,20, 10, 4)"
      ],
      "metadata": {
        "id": "vZqFGhBYxg9y",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4eef27f-e69e-4325-e667-5f9712e52ace"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conjunto de teste 1\n",
            "Média de Acurácia: 0.8316096866096865\n",
            "Média de Recall: 0.8316096866096865\n",
            "Média de Precisão: 0.8329186364653745\n",
            "Média de F1 Score: 0.8314922997449165\n",
            "\n",
            "Conjunto de teste 2\n",
            "Média de Acurácia: 0.8310256410256411\n",
            "Média de Recall: 0.8310256410256411\n",
            "Média de Precisão: 0.8323498244767852\n",
            "Média de F1 Score: 0.8309107985676754\n",
            "\n",
            "Conjunto de treinamento 1\n",
            "Média de Acurácia: 0.9435085574572127\n",
            "Média de Recall: 0.9435085574572127\n",
            "Média de Precisão: 0.9439558833296491\n",
            "Média de F1 Score: 0.943480665149845\n",
            "\n",
            "Conjunto de treinamento 2\n",
            "Média de Acurácia: 0.9441564792176039\n",
            "Média de Recall: 0.9441564792176039\n",
            "Média de Precisão: 0.9446649002759488\n",
            "Média de F1 Score: 0.9441317971745363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultados = decision_tree(X_train, y_train, X_test, y_test,30, 10, 1)"
      ],
      "metadata": {
        "id": "g_TgPH-TxgcR",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a291035c-920c-4430-8c92-33baf3a65943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conjunto de teste 1\n",
            "Média de Acurácia: 0.8249002849002848\n",
            "Média de Recall: 0.8249002849002848\n",
            "Média de Precisão: 0.8260413294782909\n",
            "Média de F1 Score: 0.8247988277686379\n",
            "\n",
            "Conjunto de teste 2\n",
            "Média de Acurácia: 0.8248717948717949\n",
            "Média de Recall: 0.8248717948717949\n",
            "Média de Precisão: 0.8257847994392898\n",
            "Média de F1 Score: 0.8247831862586885\n",
            "\n",
            "Conjunto de treinamento 1\n",
            "Média de Acurácia: 0.9653056234718825\n",
            "Média de Recall: 0.9653056234718825\n",
            "Média de Precisão: 0.9655350303150947\n",
            "Média de F1 Score: 0.9652965516459724\n",
            "\n",
            "Conjunto de treinamento 2\n",
            "Média de Acurácia: 0.9668459657701711\n",
            "Média de Recall: 0.9668459657701711\n",
            "Média de Precisão: 0.9670765508497674\n",
            "Média de F1 Score: 0.9668391487046284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultados = decision_tree(X_train, y_train, X_test, y_test,None, 5, 2)"
      ],
      "metadata": {
        "id": "Q6m7U6I8xgRj",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14de0f80-bd59-41b3-8d78-384e55780f0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conjunto de teste 1\n",
            "Média de Acurácia: 0.8261680911680912\n",
            "Média de Recall: 0.8261680911680912\n",
            "Média de Precisão: 0.8278273697704052\n",
            "Média de F1 Score: 0.826016109763967\n",
            "\n",
            "Conjunto de teste 2\n",
            "Média de Acurácia: 0.8248290598290599\n",
            "Média de Recall: 0.8248290598290599\n",
            "Média de Precisão: 0.8269813367691783\n",
            "Média de F1 Score: 0.8246186031484504\n",
            "\n",
            "Conjunto de treinamento 1\n",
            "Média de Acurácia: 0.9738141809290951\n",
            "Média de Recall: 0.9738141809290951\n",
            "Média de Precisão: 0.9744668596887497\n",
            "Média de F1 Score: 0.9737972658777369\n",
            "\n",
            "Conjunto de treinamento 2\n",
            "Média de Acurácia: 0.9726161369193155\n",
            "Média de Recall: 0.9726161369193155\n",
            "Média de Precisão: 0.9733964455106272\n",
            "Média de F1 Score: 0.9725947903657578\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultados = decision_tree(X_train, y_train, X_test, y_test,10, 5, 4)"
      ],
      "metadata": {
        "id": "q9undsxKxgDi",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99e084c1-2832-4140-ea44-85ccc0e37d33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conjunto de teste 1\n",
            "Média de Acurácia: 0.8314957264957265\n",
            "Média de Recall: 0.8314957264957265\n",
            "Média de Precisão: 0.8328778591157345\n",
            "Média de F1 Score: 0.8313769601059862\n",
            "\n",
            "Conjunto de teste 2\n",
            "Média de Acurácia: 0.8291595441595442\n",
            "Média de Recall: 0.8291595441595442\n",
            "Média de Precisão: 0.8307116785051122\n",
            "Média de F1 Score: 0.8290142145277443\n",
            "\n",
            "Conjunto de treinamento 1\n",
            "Média de Acurácia: 0.9479339853300734\n",
            "Média de Recall: 0.9479339853300734\n",
            "Média de Precisão: 0.9485672316197423\n",
            "Média de F1 Score: 0.9478999097553533\n",
            "\n",
            "Conjunto de treinamento 2\n",
            "Média de Acurácia: 0.9480317848410758\n",
            "Média de Recall: 0.9480317848410758\n",
            "Média de Precisão: 0.9486089641567765\n",
            "Média de F1 Score: 0.9480017014336702\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gmx71dL5dgE"
      },
      "source": [
        "#Gráficos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lcFip8K5kGU"
      },
      "source": [
        "Função para gerar gráfico de barra para KNN,Rede Neural e Árvore de decisão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lImLIMP5lZ9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def calcular_metricas_medias(lista):\n",
        "    \"\"\"\n",
        "    Calcula as métricas médias a partir de uma lista de tuplas contendo métricas.\n",
        "\n",
        "    :param lista: Lista de tuplas no formato (accuracy, recall, precision, f1_score).\n",
        "    :return: Tupla contendo as métricas médias (accuracy, recall, precision, f1_score).\n",
        "    \"\"\"\n",
        "    if len(lista) == 0:\n",
        "        return np.zeros(4)\n",
        "\n",
        "    metrics = np.array(lista)\n",
        "    mean_metrics = np.mean(metrics, axis=0)\n",
        "    return mean_metrics\n",
        "\n",
        "def gerar_graficos_de_barras(results, metric_names, model_names):\n",
        "    \"\"\"\n",
        "    Gera gráficos de barras para as métricas médias de desempenho dos modelos.\n",
        "\n",
        "    :param results: Lista de listas de tuplas contendo os resultados das métricas.\n",
        "                    Cada sublista corresponde aos resultados de um modelo.\n",
        "                    Cada tupla deve estar no formato (accuracy, recall, precision, f1_score).\n",
        "    :param metric_names: Lista com os nomes das métricas.\n",
        "    :param model_names: Lista com os nomes dos modelos correspondentes às sublistas de resultados.\n",
        "    \"\"\"\n",
        "    num_models = len(results)\n",
        "    num_metrics = len(metric_names)\n",
        "\n",
        "    avg_metrics = np.zeros((num_models, num_metrics))\n",
        "\n",
        "    for model_idx, model_results in enumerate(results):\n",
        "        avg_metrics[model_idx] = calcular_metricas_medias(model_results)\n",
        "\n",
        "    # Configuração do gráfico de barras\n",
        "    x = np.arange(num_models)\n",
        "    width = 0.2  # Largura das barras\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "    # Geração das barras para cada métrica\n",
        "    for i in range(num_metrics):\n",
        "        bars = ax.bar(x + i * width, avg_metrics[:, i], width, label=metric_names[i])\n",
        "\n",
        "        # Adicionando os valores acima das barras\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            ax.text(bar.get_x() + bar.get_width() / 2.0, height, f'{height:.2f}', ha='center', va='bottom')\n",
        "\n",
        "    # Configurações adicionais do gráfico\n",
        "    ax.set_ylabel('Valores Médios das Métricas')\n",
        "    ax.set_title('Desempenho Médio dos Modelos')\n",
        "    ax.set_xticks(x + width * (num_metrics - 1) / 2)\n",
        "    ax.set_xticklabels(model_names)\n",
        "    ax.legend(bbox_to_anchor=(1.25,1))\n",
        "\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJk0h_4U5qPd"
      },
      "source": [
        "Plotando os gráficos de Knn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54PePvh85uMd"
      },
      "outputs": [],
      "source": [
        "# Passando as listas de resultados para a função\n",
        "results = knn(1)\n",
        "\n",
        "metric_names = ['Acurácia', 'Recall', 'Precisão', 'F1-Score']\n",
        "model_names = ['Conjunto de teste 1', 'Conjunto de teste 2','Conjunto de treinamento 1', 'Conjunto de treinamento 2']\n",
        "\n",
        "gerar_graficos_de_barras(results, metric_names, model_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjvzR-_y5u81"
      },
      "source": [
        "Plotando os gráficos de Rede Neural"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wGhuuB5r5x9-"
      },
      "outputs": [],
      "source": [
        "# Passando as listas de resultados para a função\n",
        "results = redeNeural(20,'tanh')\n",
        "\n",
        "metric_names = ['Acurácia', 'Recall', 'Precisão', 'F1-Score']\n",
        "model_names = ['Conjunto de treinamento 1', 'Conjunto de treinamento 2', 'Conjunto de teste']\n",
        "\n",
        "gerar_graficos_de_barras(results, metric_names, model_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnq6rYir51gf"
      },
      "source": [
        "Plotando os gráficos de Árvore de decisão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnPj3r7q55Jm"
      },
      "outputs": [],
      "source": [
        "# Passando as listas de resultados para a função\n",
        "results = decision_tree(X_train, y_train, X_test, y_test, None, 2, 2)\n",
        "\n",
        "metric_names = ['Acurácia', 'Recall', 'Precisão', 'F1-Score']\n",
        "model_names = ['Conjunto de teste 1', 'Conjunto de teste 2', 'Conjunto de treinamento 1', 'Conjunto de treinamento 2']\n",
        "\n",
        "gerar_graficos_de_barras(results, metric_names, model_names)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}